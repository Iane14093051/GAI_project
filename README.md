# GAI_project

## Course Synopsis

The following topics are covered: operating system structures, processes and threads, process scheduling, process synchronization, deadlocks, memory management, and file systems.


## Description of labs

The overview provided here is quite brief; please refer to the PDF files and the code within each directory for more detailed information.

[Project1](https://github.com/Iane14093051/GAI_project1-3/tree/main/E14093051_GAI_Project2a) :
- The goal of this project is to develop an arithmetic text generation model using recurrent neural networks (RNNs) or similar architectures such as GRU or LSTM.
  
[Project2](https://github.com/Iane14093051/GAI_project1-3/tree/main/E14093051_GAI_Project2b) :
- The objective of this project is to develop a text summarization model utilizing a transformer-based architecture. This involves adapting the provided T5 English text generation code and employing GPT-2 for Chinese text summarization.

[Project3](https://github.com/Iane14093051/GAI_project1-3/tree/main/E14093051_GAI_Project3) :
- The objective of this project is to explore Parameter-Efficient Fine-Tuning (PEFT) techniques using the GLUE benchmark datasets to enhance model performance on various natural language processing tasks.
